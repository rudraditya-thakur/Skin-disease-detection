{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2529450,"sourceType":"datasetVersion","datasetId":1532614}],"dockerImageVersionId":30121,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization, Flatten\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model, load_model, Sequential\nimport numpy as np\nimport pandas as pd\nimport shutil\nimport time\nimport cv2 as cv2\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nimport os\nimport seaborn as sns\nsns.set_style('darkgrid')\nfrom PIL import Image\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom IPython.core.display import display, HTML\n# stop annoying tensorflow warning messages\nimport logging\nlogging.getLogger(\"tensorflow\").setLevel(logging.ERROR)","metadata":{"papermill":{"duration":5.693249,"end_time":"2021-05-21T20:58:45.358994","exception":false,"start_time":"2021-05-21T20:58:39.665745","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-19T08:43:24.424829Z","iopub.execute_input":"2023-11-19T08:43:24.425181Z","iopub.status.idle":"2023-11-19T08:43:24.434307Z","shell.execute_reply.started":"2023-11-19T08:43:24.425151Z","shell.execute_reply":"2023-11-19T08:43:24.433340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_image_samples(gen ):\n    t_dict=gen.class_indices\n    classes=list(t_dict.keys())    \n    images,labels=next(gen) # get a sample batch from the generator \n    plt.figure(figsize=(20, 20))\n    length=len(labels)\n    if length<25:   #show maximum of 25 images\n        r=length\n    else:\n        r=25\n    for i in range(r):\n        plt.subplot(5, 5, i + 1)\n        image=images[i]/255\n        plt.imshow(image)\n        index=np.argmax(labels[i])\n        class_name=classes[index]\n        plt.title(class_name, color='blue', fontsize=12)\n        plt.axis('off')\n    plt.show()","metadata":{"papermill":{"duration":0.03267,"end_time":"2021-05-21T20:59:58.764761","exception":false,"start_time":"2021-05-21T20:59:58.732091","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-19T08:43:27.234506Z","iopub.execute_input":"2023-11-19T08:43:27.234888Z","iopub.status.idle":"2023-11-19T08:43:27.242801Z","shell.execute_reply.started":"2023-11-19T08:43:27.234843Z","shell.execute_reply":"2023-11-19T08:43:27.241837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_images(tdir):\n    classlist=os.listdir(tdir)\n    length=len(classlist)\n    columns=5\n    rows=int(np.ceil(length/columns))    \n    plt.figure(figsize=(20, rows * 4))\n    for i, klass in enumerate(classlist):    \n        classpath=os.path.join(tdir, klass)\n        imgpath=os.path.join(classpath, '1.jpg')\n        img=plt.imread(imgpath)\n        plt.subplot(rows, columns, i+1)\n        plt.axis('off')\n        plt.title(klass, color='blue', fontsize=12)\n        plt.imshow(img)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-19T08:43:28.917328Z","iopub.execute_input":"2023-11-19T08:43:28.917679Z","iopub.status.idle":"2023-11-19T08:43:28.925000Z","shell.execute_reply.started":"2023-11-19T08:43:28.917651Z","shell.execute_reply":"2023-11-19T08:43:28.923893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_in_color(txt_msg,fore_tupple,back_tupple,):\n    #prints the text_msg in the foreground color specified by fore_tupple with the background specified by back_tupple \n    #text_msg is the text, fore_tupple is foregroud color tupple (r,g,b), back_tupple is background tupple (r,g,b)\n    rf,gf,bf=fore_tupple\n    rb,gb,bb=back_tupple\n    msg='{0}' + txt_msg\n    mat='\\33[38;2;' + str(rf) +';' + str(gf) + ';' + str(bf) + ';48;2;' + str(rb) + ';' +str(gb) + ';' + str(bb) +'m' \n    print(msg .format(mat), flush=True)\n    print('\\33[0m', flush=True) # returns default print color to back to black\n    return","metadata":{"papermill":{"duration":0.078026,"end_time":"2021-05-21T21:00:02.099684","exception":false,"start_time":"2021-05-21T21:00:02.021658","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-19T08:43:30.300352Z","iopub.execute_input":"2023-11-19T08:43:30.300713Z","iopub.status.idle":"2023-11-19T08:43:30.307224Z","shell.execute_reply.started":"2023-11-19T08:43:30.300665Z","shell.execute_reply":"2023-11-19T08:43:30.306247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LRA(keras.callbacks.Callback):\n    def __init__(self,model, base_model, patience,stop_patience, threshold, factor, dwell, batches, initial_epoch,epochs, ask_epoch):\n        super(LRA, self).__init__()\n        self.model=model\n        self.base_model=base_model\n        self.patience=patience # specifies how many epochs without improvement before learning rate is adjusted\n        self.stop_patience=stop_patience # specifies how many times to adjust lr without improvement to stop training\n        self.threshold=threshold # specifies training accuracy threshold when lr will be adjusted based on validation loss\n        self.factor=factor # factor by which to reduce the learning rate\n        self.dwell=dwell\n        self.batches=batches # number of training batch to runn per epoch\n        self.initial_epoch=initial_epoch\n        self.epochs=epochs\n        self.ask_epoch=ask_epoch\n        self.ask_epoch_initial=ask_epoch # save this value to restore if restarting training\n        # callback variables \n        self.count=0 # how many times lr has been reduced without improvement\n        self.stop_count=0        \n        self.best_epoch=1   # epoch with the lowest loss        \n        self.initial_lr=float(tf.keras.backend.get_value(model.optimizer.lr)) # get the initiallearning rate and save it         \n        self.highest_tracc=0.0 # set highest training accuracy to 0 initially\n        self.lowest_vloss=np.inf # set lowest validation loss to infinity initially\n        self.best_weights=self.model.get_weights() # set best weights to model's initial weights\n        self.initial_weights=self.model.get_weights()   # save initial weights if they have to get restored \n        \n    def on_train_begin(self, logs=None):        \n        if self.base_model != None:\n            status=base_model.trainable\n            if status:\n                msg=' initializing callback starting train with base_model trainable'\n            else:\n                msg='initializing callback starting training with base_model not trainable'\n        else:\n            msg='initialing callback and starting training'                        \n        print_in_color (msg, (244, 252, 3), (55,65,80)) \n        msg='{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^9s}{6:^9s}{7:^10s}{8:10s}{9:^8s}'.format('Epoch', 'Loss', 'Accuracy',\n                                                                                              'V_loss','V_acc', 'LR', 'Next LR', 'Monitor','% Improv', 'Duration')\n        print_in_color(msg, (244,252,3), (55,65,80)) \n        self.start_time= time.time()\n        \n    def on_train_end(self, logs=None):\n        stop_time=time.time()\n        tr_duration= stop_time- self.start_time            \n        hours = tr_duration // 3600\n        minutes = (tr_duration - (hours * 3600)) // 60\n        seconds = tr_duration - ((hours * 3600) + (minutes * 60))\n\n        self.model.set_weights(self.best_weights) # set the weights of the model to the best weights\n        msg=f'Training is completed - model is set with weights from epoch {self.best_epoch} '\n        print_in_color(msg, (0,255,0), (55,65,80))\n        msg = f'training elapsed time was {str(hours)} hours, {minutes:4.1f} minutes, {seconds:4.2f} seconds)'\n        print_in_color(msg, (0,255,0), (55,65,80))   \n        \n    def on_train_batch_end(self, batch, logs=None):\n        acc=logs.get('accuracy')* 100  # get training accuracy \n        loss=logs.get('loss')\n        msg='{0:20s}processing batch {1:4s} of {2:5s} accuracy= {3:8.3f}  loss: {4:8.5f}'.format(' ', str(batch), str(self.batches), acc, loss)\n        print(msg, '\\r', end='') # prints over on the same line to show running batch count        \n        \n    def on_epoch_begin(self,epoch, logs=None):\n        self.now= time.time()\n        \n    def on_epoch_end(self, epoch, logs=None):  # method runs on the end of each epoch\n        later=time.time()\n        duration=later-self.now \n        lr=float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n        current_lr=lr\n        v_loss=logs.get('val_loss')  # get the validation loss for this epoch\n        acc=logs.get('accuracy')  # get training accuracy \n        v_acc=logs.get('val_accuracy')\n        loss=logs.get('loss')        \n        if acc < self.threshold: # if training accuracy is below threshold adjust lr based on training accuracy\n            monitor='accuracy'\n            if epoch ==0:\n                pimprov=0.0\n            else:\n                pimprov= (acc-self.highest_tracc )*100/self.highest_tracc\n            if acc>self.highest_tracc: # training accuracy improved in the epoch                \n                self.highest_tracc=acc # set new highest training accuracy\n                self.best_weights=self.model.get_weights() # traing accuracy improved so save the weights\n                self.count=0 # set count to 0 since training accuracy improved\n                self.stop_count=0 # set stop counter to 0\n                if v_loss<self.lowest_vloss:\n                    self.lowest_vloss=v_loss\n                color= (0,255,0)\n                self.best_epoch=epoch + 1  # set the value of best epoch for this epoch              \n            else: \n                # training accuracy did not improve check if this has happened for patience number of epochs\n                # if so adjust learning rate\n                if self.count>=self.patience -1: # lr should be adjusted\n                    color=(245, 170, 66)\n                    lr= lr* self.factor # adjust the learning by factor\n                    tf.keras.backend.set_value(self.model.optimizer.lr, lr) # set the learning rate in the optimizer\n                    self.count=0 # reset the count to 0\n                    self.stop_count=self.stop_count + 1 # count the number of consecutive lr adjustments\n                    self.count=0 # reset counter\n                    if self.dwell:\n                        self.model.set_weights(self.best_weights) # return to better point in N space                        \n                    else:\n                        if v_loss<self.lowest_vloss:\n                            self.lowest_vloss=v_loss                                    \n                else:\n                    self.count=self.count +1 # increment patience counter                    \n        else: # training accuracy is above threshold so adjust learning rate based on validation loss\n            monitor='val_loss'\n            if epoch ==0:\n                pimprov=0.0\n            else:\n                pimprov= (self.lowest_vloss- v_loss )*100/self.lowest_vloss\n            if v_loss< self.lowest_vloss: # check if the validation loss improved \n                self.lowest_vloss=v_loss # replace lowest validation loss with new validation loss                \n                self.best_weights=self.model.get_weights() # validation loss improved so save the weights\n                self.count=0 # reset count since validation loss improved  \n                self.stop_count=0  \n                color=(0,255,0)                \n                self.best_epoch=epoch + 1 # set the value of the best epoch to this epoch\n            else: # validation loss did not improve\n                if self.count>=self.patience-1: # need to adjust lr\n                    color=(245, 170, 66)\n                    lr=lr * self.factor # adjust the learning rate                    \n                    self.stop_count=self.stop_count + 1 # increment stop counter because lr was adjusted \n                    self.count=0 # reset counter\n                    tf.keras.backend.set_value(self.model.optimizer.lr, lr) # set the learning rate in the optimizer\n                    if self.dwell:\n                        self.model.set_weights(self.best_weights) # return to better point in N space\n                else: \n                    self.count =self.count +1 # increment the patience counter                    \n                if acc>self.highest_tracc:\n                    self.highest_tracc= acc\n        msg=f'{str(epoch+1):^3s}/{str(self.epochs):4s} {loss:^9.3f}{acc*100:^9.3f}{v_loss:^9.5f}{v_acc*100:^9.3f}{current_lr:^9.5f}{lr:^9.5f}{monitor:^11s}{pimprov:^10.2f}{duration:^8.2f}'\n        print_in_color (msg,color, (55,65,80))\n        if self.stop_count> self.stop_patience - 1: # check if learning rate has been adjusted stop_count times with no improvement\n            msg=f' training has been halted at epoch {epoch + 1} after {self.stop_patience} adjustments of learning rate with no improvement'\n            print_in_color(msg, (0,255,255), (55,65,80))\n            self.model.stop_training = True # stop training\n        else: \n            if self.ask_epoch !=None:\n                if epoch + 1 >= self.ask_epoch:\n                    if base_model.trainable:\n                        msg='enter H to halt  or an integer for number of epochs to run then ask again'\n                    else:\n                        msg='enter H to halt ,F to fine tune model, or an integer for number of epochs to run then ask again'\n                    print_in_color(msg, (0,255,255), (55,65,80))\n                    ans=input('')\n                    if ans=='H' or ans=='h':\n                        msg=f'training has been halted at epoch {epoch + 1} due to user input'\n                        print_in_color(msg, (0,255,255), (55,65,80))\n                        self.model.stop_training = True # stop training\n                    elif ans == 'F' or ans=='f':\n                        if base_model.trainable:\n                            msg='base_model is already set as trainable'\n                        else:\n                            msg='setting base_model as trainable for fine tuning of model'\n                            self.base_model.trainable=True\n                        print_in_color(msg, (0, 255,255), (55,65,80))\n                        msg='{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^9s}{6:^9s}{7:^10s}{8:^8s}'.format('Epoch', 'Loss', 'Accuracy',\n                                                                                              'V_loss','V_acc', 'LR', 'Next LR', 'Monitor','% Improv', 'Duration')\n                        print_in_color(msg, (244,252,3), (55,65,80))                         \n                        self.count=0\n                        self.stop_count=0                        \n                        self.ask_epoch = epoch + 1 + self.ask_epoch_initial \n                        \n                    else:\n                        ans=int(ans)\n                        self.ask_epoch +=ans\n                        msg=f' training will continue until epoch ' + str(self.ask_epoch)                         \n                        print_in_color(msg, (0, 255,255), (55,65,80))\n                        msg='{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^9s}{6:^9s}{7:^10s}{8:10s}{9:^8s}'.format('Epoch', 'Loss', 'Accuracy',\n                                                                                              'V_loss','V_acc', 'LR', 'Next LR', 'Monitor','% Improv', 'Duration')\n                        print_in_color(msg, (244,252,3), (55,65,80)) ","metadata":{"execution":{"iopub.status.busy":"2023-11-19T08:43:33.548951Z","iopub.execute_input":"2023-11-19T08:43:33.549298Z","iopub.status.idle":"2023-11-19T08:43:33.594153Z","shell.execute_reply.started":"2023-11-19T08:43:33.549269Z","shell.execute_reply":"2023-11-19T08:43:33.593230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tr_plot(tr_data, start_epoch):\n    #Plot the training and validation data\n    tacc=tr_data.history['accuracy']\n    tloss=tr_data.history['loss']\n    vacc=tr_data.history['val_accuracy']\n    vloss=tr_data.history['val_loss']\n    Epoch_count=len(tacc)+ start_epoch\n    Epochs=[]\n    for i in range (start_epoch ,Epoch_count):\n        Epochs.append(i+1)   \n    index_loss=np.argmin(vloss)#  this is the epoch with the lowest validation loss\n    val_lowest=vloss[index_loss]\n    index_acc=np.argmax(vacc)\n    acc_highest=vacc[index_acc]\n    plt.style.use('fivethirtyeight')\n    sc_label='best epoch= '+ str(index_loss+1 +start_epoch)\n    vc_label='best epoch= '+ str(index_acc + 1+ start_epoch)\n    fig,axes=plt.subplots(nrows=1, ncols=2, figsize=(20,8))\n    axes[0].plot(Epochs,tloss, 'r', label='Training loss')\n    axes[0].plot(Epochs,vloss,'g',label='Validation loss' )\n    axes[0].scatter(index_loss+1 +start_epoch,val_lowest, s=150, c= 'blue', label=sc_label)\n    axes[0].set_title('Training and Validation Loss')\n    axes[0].set_xlabel('Epochs')\n    axes[0].set_ylabel('Loss')\n    axes[0].legend()\n    axes[1].plot (Epochs,tacc,'r',label= 'Training Accuracy')\n    axes[1].plot (Epochs,vacc,'g',label= 'Validation Accuracy')\n    axes[1].scatter(index_acc+1 +start_epoch,acc_highest, s=150, c= 'blue', label=vc_label)\n    axes[1].set_title('Training and Validation Accuracy')\n    axes[1].set_xlabel('Epochs')\n    axes[1].set_ylabel('Accuracy')\n    axes[1].legend()\n    plt.tight_layout\n    #plt.style.use('fivethirtyeight')\n    plt.show()\n","metadata":{"papermill":{"duration":3.215798,"end_time":"2021-05-21T22:17:13.46258","exception":false,"start_time":"2021-05-21T22:17:10.246782","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-19T08:43:34.192661Z","iopub.execute_input":"2023-11-19T08:43:34.193080Z","iopub.status.idle":"2023-11-19T08:43:34.206148Z","shell.execute_reply.started":"2023-11-19T08:43:34.193043Z","shell.execute_reply":"2023-11-19T08:43:34.205209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_info( test_gen, preds, print_code, save_dir, subject ):\n    class_dict=test_gen.class_indices\n    labels= test_gen.labels\n    file_names= test_gen.filenames \n    error_list=[]\n    true_class=[]\n    pred_class=[]\n    prob_list=[]\n    new_dict={}\n    error_indices=[]\n    y_pred=[]\n    for key,value in class_dict.items():\n        new_dict[value]=key             # dictionary {integer of class number: string of class name}\n    # store new_dict as a text fine in the save_dir\n    classes=list(new_dict.values())     # list of string of class names     \n    errors=0      \n    for i, p in enumerate(preds):\n        pred_index=np.argmax(p)         \n        true_index=labels[i]  # labels are integer values\n        if pred_index != true_index: # a misclassification has occurred\n            error_list.append(file_names[i])\n            true_class.append(new_dict[true_index])\n            pred_class.append(new_dict[pred_index])\n            prob_list.append(p[pred_index])\n            error_indices.append(true_index)            \n            errors=errors + 1\n        y_pred.append(pred_index)    \n    if print_code !=0:\n        if errors>0:\n            if print_code>errors:\n                r=errors\n            else:\n                r=print_code           \n            msg='{0:^28s}{1:^28s}{2:^28s}{3:^16s}'.format('Filename', 'Predicted Class' , 'True Class', 'Probability')\n            print_in_color(msg, (0,255,0),(55,65,80))\n            for i in range(r):                \n                split1=os.path.split(error_list[i])                \n                split2=os.path.split(split1[0])                \n                fname=split2[1] + '/' + split1[1]\n                msg='{0:^28s}{1:^28s}{2:^28s}{3:4s}{4:^6.4f}'.format(fname, pred_class[i],true_class[i], ' ', prob_list[i])\n                print_in_color(msg, (255,255,255), (55,65,60))\n                #print(error_list[i]  , pred_class[i], true_class[i], prob_list[i])               \n        else:\n            msg='With accuracy of 100 % there are no errors to print'\n            print_in_color(msg, (0,255,0),(55,65,80))\n    if errors>0:\n        plot_bar=[]\n        plot_class=[]\n        for  key, value in new_dict.items():        \n            count=error_indices.count(key) \n            if count!=0:\n                plot_bar.append(count) # list containg how many times a class c had an error\n                plot_class.append(value)   # stores the class \n        fig=plt.figure()\n        fig.set_figheight(len(plot_class)/3)\n        fig.set_figwidth(10)\n        plt.style.use('fivethirtyeight')\n        for i in range(0, len(plot_class)):\n            c=plot_class[i]\n            x=plot_bar[i]\n            plt.barh(c, x, )\n            plt.title( ' Errors by Class on Test Set')\n    y_true= np.array(labels)        \n    y_pred=np.array(y_pred)\n    if len(classes)<= 30:\n        # create a confusion matrix \n        cm = confusion_matrix(y_true, y_pred )        \n        length=len(classes)\n        if length<8:\n            fig_width=8\n            fig_height=8\n        else:\n            fig_width= int(length * .5)\n            fig_height= int(length * .5)\n        plt.figure(figsize=(fig_width, fig_height))\n        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n        plt.xticks(np.arange(length)+.5, classes, rotation= 90)\n        plt.yticks(np.arange(length)+.5, classes, rotation=0)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Actual\")\n        plt.title(\"Confusion Matrix\")\n        plt.show()\n    clr = classification_report(y_true, y_pred, target_names=classes)\n    print(\"Classification Report:\\n----------------------\\n\", clr)","metadata":{"papermill":{"duration":3.03999,"end_time":"2021-05-21T22:17:25.43058","exception":false,"start_time":"2021-05-21T22:17:22.39059","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-19T08:43:35.116945Z","iopub.execute_input":"2023-11-19T08:43:35.117270Z","iopub.status.idle":"2023-11-19T08:43:35.139035Z","shell.execute_reply.started":"2023-11-19T08:43:35.117241Z","shell.execute_reply":"2023-11-19T08:43:35.137962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def saver(save_path, model, model_name, subject, accuracy,img_size, scalar, generator):\n    # first save the model\n    save_id=str (model_name +  '-' + subject +'-'+ str(acc)[:str(acc).rfind('.')+3] + '.h5')\n    model_save_loc=os.path.join(save_path, save_id)\n    model.save(model_save_loc)\n    print_in_color ('model was saved as ' + model_save_loc, (0,255,0),(55,65,80)) \n    # now create the class_df and convert to csv file    \n    class_dict=generator.class_indices \n    height=[]\n    width=[]\n    scale=[]\n    for i in range(len(class_dict)):\n        height.append(img_size[0])\n        width.append(img_size[1])\n        scale.append(scalar)\n    Index_series=pd.Series(list(class_dict.values()), name='class_index')\n    Class_series=pd.Series(list(class_dict.keys()), name='class') \n    Height_series=pd.Series(height, name='height')\n    Width_series=pd.Series(width, name='width')\n    Scale_series=pd.Series(scale, name='scale by')\n    class_df=pd.concat([Index_series, Class_series, Height_series, Width_series, Scale_series], axis=1)    \n    csv_name='class_dict.csv'\n    csv_save_loc=os.path.join(save_path, csv_name)\n    class_df.to_csv(csv_save_loc, index=False) \n    print_in_color ('class csv file was saved as ' + csv_save_loc, (0,255,0),(55,65,80)) \n    return model_save_loc, csv_save_loc","metadata":{"execution":{"iopub.status.busy":"2023-11-19T08:43:35.626127Z","iopub.execute_input":"2023-11-19T08:43:35.626511Z","iopub.status.idle":"2023-11-19T08:43:35.637688Z","shell.execute_reply.started":"2023-11-19T08:43:35.626477Z","shell.execute_reply":"2023-11-19T08:43:35.636816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predictor(sdir, csv_path,  model_path, crop_image = False):    \n    # read in the csv file\n    class_df=pd.read_csv(csv_path)    \n    img_height=int(class_df['height'].iloc[0])\n    img_width =int(class_df['width'].iloc[0])\n    img_size=(img_width, img_height)\n    scale=class_df['scale by'].iloc[0] \n    try: \n        s=int(scale)\n        s2=1\n        s1=0\n    except:\n        split=scale.split('-')\n        s1=float(split[1])\n        s2=float(split[0].split('*')[1]) \n        print (s1,s2)\n    path_list=[]\n    paths=os.listdir(sdir)\n    for f in paths:\n        path_list.append(os.path.join(sdir,f))\n    print (' Model is being loaded- this will take about 10 seconds')\n    model=load_model(model_path)\n    image_count=len(path_list)    \n    index_list=[] \n    prob_list=[]\n    cropped_image_list=[]\n    good_image_count=0\n    for i in range (image_count):       \n        img=cv2.imread(path_list[i])\n        if crop_image == True:\n            status, img=crop(img)\n        else:\n            status=True\n        if status== True:\n            good_image_count +=1\n            img=cv2.resize(img, img_size)            \n            cropped_image_list.append(img)\n            img=img*s2 - s1\n            img=np.expand_dims(img, axis=0)\n            p= np.squeeze (model.predict(img))           \n            index=np.argmax(p)            \n            prob=p[index]\n            index_list.append(index)\n            prob_list.append(prob)\n    if good_image_count==1:\n        class_name= class_df['class'].iloc[index_list[0]]\n        probability= prob_list[0]\n        img=cropped_image_list [0] \n        plt.title(class_name, color='blue', fontsize=16)\n        plt.axis('off')\n        plt.imshow(img)\n        return class_name, probability\n    elif good_image_count == 0:\n        return None, None\n    most=0\n    for i in range (len(index_list)-1):\n        key= index_list[i]\n        keycount=0\n        for j in range (i+1, len(index_list)):\n            nkey= index_list[j]            \n            if nkey == key:\n                keycount +=1                \n        if keycount> most:\n            most=keycount\n            isave=i             \n    best_index=index_list[isave]    \n    psum=0\n    bestsum=0\n    for i in range (len(index_list)):\n        psum += prob_list[i]\n        if index_list[i]==best_index:\n            bestsum += prob_list[i]  \n    img= cropped_image_list[isave]/255    \n    class_name=class_df['class'].iloc[best_index]\n    plt.title(class_name, color='blue', fontsize=16)\n    plt.axis('off')\n    plt.imshow(img)\n    return class_name, bestsum/image_count","metadata":{"execution":{"iopub.status.busy":"2023-11-19T08:43:36.088956Z","iopub.execute_input":"2023-11-19T08:43:36.089316Z","iopub.status.idle":"2023-11-19T08:43:36.107384Z","shell.execute_reply.started":"2023-11-19T08:43:36.089282Z","shell.execute_reply":"2023-11-19T08:43:36.106515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def trim (df, max_size, min_size, column):\n    df=df.copy()\n    sample_list=[] \n    groups=df.groupby(column)\n    for label in df[column].unique():        \n        group=groups.get_group(label)\n        sample_count=len(group)         \n        if sample_count> max_size :\n            samples=group.sample(max_size, replace=False, weights=None, random_state=123, axis=0).reset_index(drop=True)\n            sample_list.append(samples)\n        elif sample_count>= min_size:\n            sample_list.append(group)\n    df=pd.concat(sample_list, axis=0).reset_index(drop=True)\n    balance=list(df[column].value_counts())\n    print (balance)\n    return df","metadata":{"execution":{"iopub.status.busy":"2023-11-19T08:43:36.495388Z","iopub.execute_input":"2023-11-19T08:43:36.495752Z","iopub.status.idle":"2023-11-19T08:43:36.503512Z","shell.execute_reply.started":"2023-11-19T08:43:36.495717Z","shell.execute_reply":"2023-11-19T08:43:36.502595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fpath=r'../input/skin-diseases-image-dataset/IMG_CLASSES/2. Melanoma 15.75k/ISIC_6652710.jpg'\nimg=plt.imread(fpath)\nprint (img.shape)\nimshow(img)\n","metadata":{"papermill":{"duration":0.393288,"end_time":"2021-05-21T20:58:45.889884","exception":false,"start_time":"2021-05-21T20:58:45.496596","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-19T08:43:43.645675Z","iopub.execute_input":"2023-11-19T08:43:43.646090Z","iopub.status.idle":"2023-11-19T08:43:44.040659Z","shell.execute_reply.started":"2023-11-19T08:43:43.646053Z","shell.execute_reply":"2023-11-19T08:43:44.039786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess (sdir, trsplit, vsplit):\n    filepaths=[]\n    labels=[]    \n    classlist=os.listdir(sdir)\n    for klass in classlist:\n        classpath=os.path.join(sdir,klass)\n        flist=os.listdir(classpath)\n        for f in flist:\n            fpath=os.path.join(classpath,f)\n            filepaths.append(fpath)\n            labels.append(klass)\n    Fseries=pd.Series(filepaths, name='filepaths')\n    Lseries=pd.Series(labels, name='labels')\n    df=pd.concat([Fseries, Lseries], axis=1)       \n    # split df into train_df and test_df \n    dsplit=vsplit/(1-trsplit)\n    strat=df['labels']    \n    train_df, dummy_df=train_test_split(df, train_size=trsplit, shuffle=True, random_state=123, stratify=strat)\n    strat=dummy_df['labels']\n    valid_df, test_df=train_test_split(dummy_df, train_size=dsplit, shuffle=True, random_state=123, stratify=strat)\n    print('train_df length: ', len(train_df), '  test_df length: ',len(test_df), '  valid_df length: ', len(valid_df))\n    print(train_df['labels'].value_counts())\n    return train_df, test_df, valid_df\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-19T08:43:44.042286Z","iopub.execute_input":"2023-11-19T08:43:44.042671Z","iopub.status.idle":"2023-11-19T08:43:44.052159Z","shell.execute_reply.started":"2023-11-19T08:43:44.042632Z","shell.execute_reply":"2023-11-19T08:43:44.051314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sdir=r'../input/skin-diseases-image-dataset/IMG_CLASSES'\ntrain_df, test_df, valid_df= preprocess(sdir, .8,.1)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T08:43:53.493237Z","iopub.execute_input":"2023-11-19T08:43:53.493597Z","iopub.status.idle":"2023-11-19T08:43:57.865275Z","shell.execute_reply.started":"2023-11-19T08:43:53.493566Z","shell.execute_reply":"2023-11-19T08:43:57.864384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def balance(train_df,max_samples, min_samples, column, working_dir, image_size):\n    train_df=train_df.copy()\n    train_df=trim (train_df, max_samples, min_samples, column)    \n    # make directories to store augmented images\n    aug_dir=os.path.join(working_dir, 'aug')\n    if os.path.isdir(aug_dir):\n        shutil.rmtree(aug_dir)\n    os.mkdir(aug_dir)\n    for label in train_df['labels'].unique():    \n        dir_path=os.path.join(aug_dir,label)    \n        os.mkdir(dir_path)\n    # create and store the augmented images     \n    gen=ImageDataGenerator(horizontal_flip=True,  rotation_range=20, width_shift_range=.2,\n                                  height_shift_range=.2, zoom_range=.2)\n    groups=train_df.groupby('labels') # group by class\n    for label in train_df['labels'].unique():  # for every class        \n        group=groups.get_group(label)  # a dataframe holding only rows with the specified label \n        sample_count=len(group)   # determine how many samples there are in this class  \n        if sample_count< max_samples: # if the class has less than target number of images\n            aug_img_count=0\n            delta=max_samples-sample_count  # number of augmented images to create\n            target_dir=os.path.join(aug_dir, label)  # define where to write the images    \n            aug_gen=gen.flow_from_dataframe( group,  x_col='filepaths', y_col=None, target_size=image_size,\n                                            class_mode=None, batch_size=1, shuffle=False, \n                                            save_to_dir=target_dir, save_prefix='aug-', color_mode='rgb',\n                                            save_format='jpg')\n            while aug_img_count<delta:\n                images=next(aug_gen)            \n                aug_img_count += len(images)            \n    # create aug_df and merge with train_df to create composite training set ndf\n    aug_fpaths=[]\n    aug_labels=[]\n    classlist=os.listdir(aug_dir)\n    for klass in classlist:\n        classpath=os.path.join(aug_dir, klass)     \n        flist=os.listdir(classpath)    \n        for f in flist:        \n            fpath=os.path.join(classpath,f)         \n            aug_fpaths.append(fpath)\n            aug_labels.append(klass)\n    Fseries=pd.Series(aug_fpaths, name='filepaths')\n    Lseries=pd.Series(aug_labels, name='labels')\n    aug_df=pd.concat([Fseries, Lseries], axis=1)    \n    ndf=pd.concat([train_df,aug_df], axis=0).reset_index(drop=True)\n    print (list(ndf['labels'].value_counts()) )\n    return ndf ","metadata":{"execution":{"iopub.status.busy":"2023-11-19T08:43:57.866614Z","iopub.execute_input":"2023-11-19T08:43:57.866926Z","iopub.status.idle":"2023-11-19T08:43:57.880960Z","shell.execute_reply.started":"2023-11-19T08:43:57.866897Z","shell.execute_reply":"2023-11-19T08:43:57.880023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_samples= 1006\nmin_samples=0\ncolumn='labels'\nworking_dir = r'./'\nimg_size=(300, 300)\nndf=balance(train_df,max_samples, min_samples, column, working_dir, img_size)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T08:43:57.882856Z","iopub.execute_input":"2023-11-19T08:43:57.883232Z","iopub.status.idle":"2023-11-19T08:43:57.950504Z","shell.execute_reply.started":"2023-11-19T08:43:57.883195Z","shell.execute_reply":"2023-11-19T08:43:57.949500Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"channels=3\nbatch_size=30\nimg_shape=(img_size[0], img_size[1], channels)\nlength=len(test_df)\ntest_batch_size=sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and length/n<=80],reverse=True)[0]  \ntest_steps=int(length/test_batch_size)\nprint ( 'test batch size: ' ,test_batch_size, '  test steps: ', test_steps)\ndef scalar(img):    \n    return img  # EfficientNet expects pixelsin range 0 to 255 so no scaling is required\ntrgen=ImageDataGenerator(preprocessing_function=scalar, horizontal_flip=True)\ntvgen=ImageDataGenerator(preprocessing_function=scalar)\ntrain_gen=trgen.flow_from_dataframe( ndf, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical',\n                                    color_mode='rgb', shuffle=True, batch_size=batch_size)\ntest_gen=tvgen.flow_from_dataframe( test_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical',\n                                    color_mode='rgb', shuffle=False, batch_size=test_batch_size)\n\nvalid_gen=tvgen.flow_from_dataframe( valid_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical',\n                                    color_mode='rgb', shuffle=True, batch_size=batch_size)\nclasses=list(train_gen.class_indices.keys())\nclass_count=len(classes)\ntrain_steps=int(np.ceil(len(train_gen.labels)/batch_size))","metadata":{"execution":{"iopub.status.busy":"2023-11-19T08:43:58.833671Z","iopub.execute_input":"2023-11-19T08:43:58.834064Z","iopub.status.idle":"2023-11-19T08:44:44.056497Z","shell.execute_reply.started":"2023-11-19T08:43:58.834030Z","shell.execute_reply":"2023-11-19T08:44:44.055523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show_image_samples(train_gen)","metadata":{"papermill":{"duration":3.031821,"end_time":"2021-05-21T21:00:01.820151","exception":false,"start_time":"2021-05-21T20:59:58.78833","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-19T08:44:44.058119Z","iopub.execute_input":"2023-11-19T08:44:44.058411Z","iopub.status.idle":"2023-11-19T08:44:44.062544Z","shell.execute_reply.started":"2023-11-19T08:44:44.058381Z","shell.execute_reply":"2023-11-19T08:44:44.061586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name='EfficientNetB3'\nbase_model=tf.keras.applications.EfficientNetB2(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max') \nx=base_model.output\nx=keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\nx = Dense(256, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n                bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\nx=Dropout(rate=.45, seed=123)(x)        \noutput=Dense(class_count, activation='softmax')(x)\nmodel=Model(inputs=base_model.input, outputs=output)\nmodel.compile(Adamax(lr=.001), loss='categorical_crossentropy', metrics=['accuracy']) ","metadata":{"papermill":{"duration":5.559742,"end_time":"2021-05-21T21:00:07.864272","exception":false,"start_time":"2021-05-21T21:00:02.30453","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-19T08:44:44.064129Z","iopub.execute_input":"2023-11-19T08:44:44.064480Z","iopub.status.idle":"2023-11-19T08:44:50.794760Z","shell.execute_reply.started":"2023-11-19T08:44:44.064444Z","shell.execute_reply":"2023-11-19T08:44:50.793986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 30\npatience = 1\nstop_patience = 3\nthreshold = 0.9\nfactor = 0.5\ndwell = True\nfreeze = False\nask_epoch = 50\nbatches = train_steps\ncallbacks = [\n    LRA(model=model, base_model=base_model, patience=patience, stop_patience=stop_patience, threshold=threshold,\n        factor=factor, dwell=dwell, batches=batches, initial_epoch=0, epochs=epochs, ask_epoch=ask_epoch)\n]\nhistory = model.fit(\n    x=train_gen,\n    epochs=epochs,\n    verbose=0,\n    callbacks=callbacks,\n    validation_data=valid_gen,\n    validation_steps=None,\n    shuffle=False,\n    initial_epoch=0\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T08:45:07.594940Z","iopub.execute_input":"2023-11-19T08:45:07.595308Z","iopub.status.idle":"2023-11-19T09:38:46.056719Z","shell.execute_reply.started":"2023-11-19T08:45:07.595278Z","shell.execute_reply":"2023-11-19T09:38:46.055802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr_plot(history,0)\nsubject='skin disease'\nacc=model.evaluate( test_gen, batch_size=test_batch_size, verbose=1, steps=test_steps, return_dict=False)[1]*100\nmsg=f'accuracy on the test set is {acc:5.2f} %'\nprint_in_color(msg, (0,255,0),(55,65,80))\ngenerator=train_gen\nscale = 1\nmodel_save_loc, csv_save_loc=saver(working_dir, model, model_name, subject, acc, img_size, scale,  generator)","metadata":{"papermill":{"duration":14.533987,"end_time":"2021-05-21T22:17:49.515069","exception":false,"start_time":"2021-05-21T22:17:34.981082","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-19T09:38:46.058554Z","iopub.execute_input":"2023-11-19T09:38:46.058911Z","iopub.status.idle":"2023-11-19T09:39:54.670601Z","shell.execute_reply.started":"2023-11-19T09:38:46.058872Z","shell.execute_reply":"2023-11-19T09:39:54.669835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_code=0\npreds=model.predict(test_gen, steps=test_steps, verbose=1) \nprint_info( test_gen, preds, print_code, working_dir, subject )  ","metadata":{"papermill":{"duration":8.948725,"end_time":"2021-05-21T22:18:07.482198","exception":false,"start_time":"2021-05-21T22:17:58.533473","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-19T09:40:58.602381Z","iopub.execute_input":"2023-11-19T09:40:58.602715Z","iopub.status.idle":"2023-11-19T09:41:36.706783Z","shell.execute_reply.started":"2023-11-19T09:40:58.602687Z","shell.execute_reply":"2023-11-19T09:41:36.705917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"store_path=os.path.join(working_dir, 'storage')\nif os.path.isdir(store_path):\n    shutil.rmtree(store_path)\nos.mkdir(store_path)\n# input an image of a melanoma\nimg_path=r'../input/skin-diseases-image-dataset/IMG_CLASSES/2. Melanoma 15.75k/ISIC_6654565.jpg'\nimg=cv2.imread(img_path,  cv2.IMREAD_REDUCED_COLOR_2)\nimg=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n# model was trained on rgb images so convert image to rgb\nfile_name=os.path.split(img_path)[1]\ndst_path=os.path.join(store_path, file_name)\ncv2.imwrite(dst_path, img)\n# check if the directory was created and image stored\nprint (os.listdir(store_path))","metadata":{"execution":{"iopub.status.busy":"2023-11-19T09:41:46.876318Z","iopub.execute_input":"2023-11-19T09:41:46.876658Z","iopub.status.idle":"2023-11-19T09:41:46.985615Z","shell.execute_reply.started":"2023-11-19T09:41:46.876629Z","shell.execute_reply":"2023-11-19T09:41:46.984580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"csv_path=csv_save_loc # path to class_dict.csv\nmodel_path=model_save_loc # path to the trained model\nclass_name, probability=predictor(store_path, csv_path,  model_path, crop_image = False) # run the classifier\nmsg=f' image is of class {class_name} with a probability of {probability * 100: 6.2f} %'\nprint_in_color(msg, (0,255,255), (65,85,55))","metadata":{"execution":{"iopub.status.busy":"2023-11-19T09:41:57.170543Z","iopub.execute_input":"2023-11-19T09:41:57.170911Z","iopub.status.idle":"2023-11-19T09:42:03.265433Z","shell.execute_reply.started":"2023-11-19T09:41:57.170874Z","shell.execute_reply":"2023-11-19T09:42:03.264486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cd /kaggle/working/aug","metadata":{"execution":{"iopub.status.busy":"2023-11-19T10:36:58.132948Z","iopub.execute_input":"2023-11-19T10:36:58.133394Z","iopub.status.idle":"2023-11-19T10:36:59.147557Z","shell.execute_reply.started":"2023-11-19T10:36:58.133292Z","shell.execute_reply":"2023-11-19T10:36:59.146501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2023-11-19T09:44:49.086614Z","iopub.execute_input":"2023-11-19T09:44:49.086981Z","iopub.status.idle":"2023-11-19T09:44:50.123098Z","shell.execute_reply.started":"2023-11-19T09:44:49.086947Z","shell.execute_reply":"2023-11-19T09:44:50.122056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'EfficientNetB3-skin disease-82.87.h5')","metadata":{"execution":{"iopub.status.busy":"2023-11-19T09:45:11.677485Z","iopub.execute_input":"2023-11-19T09:45:11.677949Z","iopub.status.idle":"2023-11-19T09:45:11.685456Z","shell.execute_reply.started":"2023-11-19T09:45:11.677906Z","shell.execute_reply":"2023-11-19T09:45:11.684503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}